Metadata-Version: 2.1
Name: wordhoard
Version: 1.5.3
Summary: A comprehensive lexical discovery application that is useful for finding semantic relationships such as, the antonyms, synonyms, hypernyms, hyponyms, homophones and definitions for a specific word.
Home-page: https://github.com/johnbumgarner/wordhoard
Author: John Bumgarner
Author-email: wordhoardproject@gmail.com
License: LICENSE.txt
Keywords: antonyms,bag of words,definitions,hypernyms,hyponyms,homophones,information retrieval,lexicon,semantic relationships,synonyms,natural language processing
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Text Processing :: General
Classifier: Topic :: Text Processing :: Linguistic
Classifier: Topic :: Utilities
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: backoff (>=2.2.1)
Requires-Dist: beautifulsoup4 (>=4.11.2)
Requires-Dist: certifi (>=2022.12.7)
Requires-Dist: charset-normalizer (>=3.1.0)
Requires-Dist: cloudscraper (>=1.2.69)
Requires-Dist: deckar01-ratelimit (>=3.0.2)
Requires-Dist: deepl (>=1.14.0)
Requires-Dist: idna (>=3.4)
Requires-Dist: lxml (>=4.9.2)
Requires-Dist: pyparsing (>=3.0.9)
Requires-Dist: requests (>=2.28.2)
Requires-Dist: requests-toolbelt (>=0.10.1)
Requires-Dist: soupsieve (>=2.4)
Requires-Dist: urllib3 (>=1.26.15)

# Primary Use Case
<p align="justify"> 
Textual analysis is a broad term for various research methodologies used to qualitatively describe, interpret and understand text data. These methodologies are mainly used in academic research to analyze content related to media and communication studies, popular culture, sociology, and philosophy. Textual analysis allows these researchers to quickly obtain relevant insights from unstructured data. All types of information can be gleaned from textual data, especially from social media posts or news articles. Some of this information includes the overall concept of the subtext, symbolism within the text, assumptions being made and potential relative value to a subject (e.g. data science). In some cases it is possible to deduce the relative historical and cultural context of a body of text using analysis techniques coupled with knowledge from different disciplines, like linguistics and semiotics.
   
Word frequency is the technique used in textual analysis to measure the frequency of a specific word or word grouping within unstructured data. Measuring the number of word occurrences in a corpus allows a researcher to garner interesting insights about the text. A subset of word frequency is the correlation between a given word and that word's relationship to either antonyms and synonyms within the specific corpus being analyzed. Knowing these relationships is critical to improving word frequencies and topic modeling.

<strong>Wordhoard</strong> was designed to assist researchers performing textual analysis to build more comprehensive lists of antonyms, synonyms, hypernyms, hyponyms and homophones.
</p>

# Installation

<p align="justify"> 
   Install the distribution via pip:
</p>

```python
pip3 install wordhoard
```

# General Package Utilization

<p align="justify">
Please reference the <a href="https://wordhoard.readthedocs.io/en/latest" target="_blank">WordHoard Documentation</a> for package usage guidance and parameters.
</p>

# Sources

<p align="justify">
This package is designed to query these online sources for antonyms, synonyms, hypernyms, hyponyms and definitions:

1. classicthesaurus.com
2. collinsdictionary.com
3. merriam-webster.com
4. synonym.com
5. thesaurus.com
6. wordhippo.com
7. wordnet.princeton.edu
</p>
  
# Dependencies

<p align="justify">
This package has these core dependencies:
  
1. backoff
2. BeautifulSoup
3. cloudscraper
4. deckar01-ratelimit
5. deepl
6. lxml
7. requests
8. urllib3

</p>

<p align="justify">
Additional details on this package's dependencies can be found <a href="https://wordhoard.readthedocs.io/en/latest/dependencies" target="_blank">here</a>.
</p>

# Development Roadmap

<p align="justify">
If you would like to contribute to the <strong>Wordhoard</strong> project please read the <a href="https://wordhoard.readthedocs.io/en/latest/contributing" target="_blank">contributing guidelines</a>.
   
Items currently under development:
   - Expanding the list of hypernyms, hyponyms and homophones
   - Adding part-of-speech filters in queries 
</p>

# Issues

<p align="justify">
This repository is actively maintained.  Feel free to open any issues related to bugs, coding errors, broken links or enhancements. 

You can also contact me at [John Bumgarner](mailto:wordhoardproject@gmail.com?subject=[GitHub]%20wordhoard%20project%20request) with any issues or enhancement requests.
</p>


# Sponsorship
   
If you would like to contribute financially to the development and maintenance of the <strong>Wordhoard</strong> project please read the <a href="https://github.com/johnbumgarner/wordhoard/blob/master/SPONSOR.md">sponsorship information</a>.

# License

<p align="justify">
The MIT License (MIT).  Please see <a href="https://wordhoard.readthedocs.io/en/latest/license" target="_blank">License File</a> for more information.
</p>


# Author

<p align="justify">
   Copyright (c) 2020 John Bumgarner 
</p>
